Eh, Por aquí veo que hay, hay personas conocidas Pues que conozco, eh? Para los que no me conocen, pues trabajo, pues en en el área de The Machine learning cierto, eh, Muy enfocada, pues al al desarrollo no solamente en hacer la exploración de los modelos, sino también en en desarrollarlos Pues en desarrollar una aplicación que que haga uso de estos modelos que los consuma entonces bueno, para para esta sesión preparé Pues un un una pequeña explicación de de lo que es trabajar con los lm lm pues sabemos que es un trending topic en estos momentos y pues idea generativa como tal trending topic por Pues por bastante rato se digamos que tiene muchos usos, tiene mucha mucha capacidad de usos, pero lo que normalmente se ve es trabajar en chats cierto en en chatbots tipo tipo empresariales preguntarle, pues cosas sobre la Data de la compañía y
Se nos da respuesta Entonces eso es lo que lo que vamos a ver un poquito y que que en muchos de sus compañías o o en las partes donde trabajen, probablemente vayan a tener ese tipo de arquitecturas en algún momento Entonces eh. Eso llama arquitecturas rack. Digo que ya lo han escuchado en algún momento, eh? Voy a dar una pequeña explicación de de cómo es este funcionamiento voy a mostrar lo arquitectura de de este pequeño framework, que preparé y luego les muestro la ejecución en el código y les pasó, pues un inclusive algo para que hagan hagamos unas pruebas eso, entonces voy a compartir pantalla, eh? Van a ver una pantalla de Paint Eh pues yo soy una persona que que le gusta mucho tratar de explicar rayando de alguna manera. Entonces, eh? Voy a hacer una una muy breve explicación Yo sé que es muy probable, que ustedes ya conozcan eso Pero cuál contexto y pues para utilizarlo en el video Entonces lo primero que que tenemos que saber es que pues vamos a trabajar con con el lm cierto los modelos grandes de lenguaje, pero
Los del lm para poder ejecutar este tipo de de modelos probabilísticos de lenguaje se suele utilizar máquinas que son muy grandes, o sea, máquinas que tienen una capacidad de procesamiento muy alto gpus que normalmente nosotros no tenemos inclusive en las compañías que nosotros trabajamos, no se tiene Pues porque nosotros normalmente trabajamos con compañías que tienen nubes o sea, ASUS sea, eh? Aws, sea, eh? La de Google o bueno prever entonces normalmente lo que hacemos o lo que más común se ve es que tomamos la Api de opening y con ella trabajamos Entonces ese es el el digamos la manera más común en la que se trabaja pero también podemos trabajar con los slm Entonces al revés que es el slm son modelos pequeños de lenguaje, o sea es básicamente lo mismo que los que los modelos grandes pero son modelos más contenidos para que se suele utilizar esto normalmente.
Utilizan para hacerle find tuning a problemas muy específicos, digamos que tengo un problema de traducción y digamos que tengo un problema de algo sencillo generar una un acuerdo y sql o necesito generar, eh? Un un pequeño fragmento de edad o hacer un json, etcétera cierto Entonces se pueden utilizar tanto los los lm como los slm entonces características de estos necesitan procesamientos grandes cierto grandes cantidades de gpu, los slm también lo ideal es que ejecuten en gpu, pero esos también se pueden ejecutar en cpu O sea si ustedes tienen un computador medianamente Bueno pues no tiene que ser un un gamer supergigante o una máquina de la NASA igual pueden en su computador corporativo pueden ejecutar un un slm Hay unos que llama el modelo fi3 que es es relativamente fácil de ejecutar, o sea, cualquier máquina, lo puede ejecutar, puede demorar obviamente un poquito más, pero pero se puede ejecutar Aunque Pues digamos que cómo va el
Acá en este momento no cada vez es más barato consumir los los lm entonces, pues es una es una opción Entonces tenemos los modelos grandes de lenguaje Estos son modelos, que pues están basados en la arquitectura, que yo creo que ya hemos visto muchas veces los Transformers empezaron por allá con un paper de Google el Bear luego pareció pene ya y empezó a sacar todo este todo este modelo gpt Y bueno, ya de ahí se empezó a a ir, se empezó a regar y luego salió otra rama que son los modelos generativos de de imagen y Bueno pero entonces nos vamos a centrar en el lm Entonces los modelos grandes del lenguaje son modelos que trabajan a base de predecir la próxima palabra que hay en en un texto cierto Entonces tú le ingresas normalmente un Pro que pues es una serie de palabras, Eh Este modelo, lo que hace es tokenizar las organizadas es convertir una palabra de estás en un vector cierto 001 000 0001 bueno así.
Es convertirlas en en un token y luego pasarlas y empezar a predecir Qué es el siguiente texto o sea, qué es lo que sigue de aquí para adelante, vemos que lo que está en rojito, es lo que el modelo está prediciendo y lo que está en negro es lo que el modelo, eh? O bueno, es el Chrome que tú le diste al modelo o o lo que tú le ingresaste cierto, él se encarga de de hacer eso modelos como el el pues el que todos conocemos el chat gpt. Eso es un modelo que ya además de tener el el modelo base del lenguaje son modelos que están que tienen un find tuning o o un entrenamiento extra para funcionar como un chat, pero no todos los lm funcionan como un chat ellos, simplemente se encargan de predecir la siguiente palabra y el precio en una cadena de palabras, pero el el chat gpt o Cloud o croc o bueno, esos modelos de chat ya lo que tienen es un fine tuning directamente para trabajar como
chat entonces esa orina, pues sus ventajas, eh, Y digamos que con nosotros utilizamos los modelos base No necesariamente funcionan como chat, sino que funcionan como completa de texto Entonces tenemos el lm o el slm O Nuestro modelo de lenguaje, llamémoslo en watch nuestro modelo de lenguaje y nosotros lo queremos fan tunear, pero no tenemos la capacidad de cómputo para hacer esto porque esto requiere una alta capacidad de cómputo Entonces ahí es donde se inventó está arquitectura que se llama rack cierto se llama rack, es arquitectura, básicamente lo que hace es, eh tomar un texto que vos quieras como contexto Entonces tienes un un una cantidad de texto grande, sea un documento muchos documentos, Por ejemplo, si estás en tu compañía y y están utilizando un S3 dws, entonces posiblemente en ese S3 tienen un montón de PDF o tienen un montón de csb, tienen un montón de
Está arquitectura de rac, lo que hace es ir tomando fragmentos de ese texto que pues tú puedes definir de varias maneras, pero ir tomando fragmentos de ese texto y cada fragmento y lo convirtiendo en un vector en un vector, eso es lo que, eh, en este tipo de arquitecturas o o bueno, van a encontrar en el medio que se llaman los Méndez porque me sobra de ahí en beings, entonces hacerla en vez de ir a un texto o hacerle en Being a cualquier cosa es pasarlo de de un contenido grande a un contenido, pues pequeño y un contenido vectorial eso es lo que hacen los envans Entonces digamos que este LLL el que estamos utilizando o slm lo que sea él tiene un espacio n-dimensional. Veámoslo aquí como si fuera de tres dimensiones Pero él en realidad tiene un espacio n-dimensional, por ejemplo chat gpt el modelo chat dpt 3.5, que pues ya inclusive está viejo ese modelo Tiene
400 con 1440 dimensiones entonces vos cuando concedes una palabra o un vector o lo que sea me perdona una palabra o una frase o lo que sea él lo convierte en un vector de 1440 y bola posiciones y digamos que esta frase de acá todo este contenido de esta frase de acá está ubicada aquí en el espacio en un punto. Quién es el espacio luego esta frasecita Acá está ubicada por aquí luego esta frasecita de acá está ubicada por acá. Luego de esta prueba por acá ubicado por acá. Él empieza a ubicar todo en el espacio por el contexto, o sea por la por las palabras o los tokens que tengan y pues ahí está, es un espacio n-dimensional aquí yo como les digo lo pinto de tres dimensiones, pero es un espacio en el dimensional Entonces cómo funciona la arquitectura de rack. Yo todas estas palabras estas frases este es estos textos como tal los convierto en vectores y los guardo en una base de datos vectorial, cuáles son?
Bases de datos vectoriales puede ser una base de datos de mongo puede ser inclusive por ahí ya vi que postres tiene un creo una nueva funcionalidad para para mediums puede ser, eh? Files que es la la de Facebook puede ser la de Google hay muchas hay muchos Ah no no es solamente, eh? Una base de datos de mongo, que pues no son tan baratas, sino que hay muchas bases de datos vectoriales entonces este puntico tiene toda la representación de esta frase y toda la metada que vos lo quieras meter cierto. Eso lo puedes asociar Entonces cuando tú le haces una pregunta a este tipo de modelo y tú llegas y le dices Pues digamos que este sea un texto de no sé tenga el código de tránsito de Colombia entonces tú le preguntas, eh? Ven Qué pasa si me pasó un semáforo en rojo en No sé bueno si me pasó un semáforo en rojo en general, Qué pasa me pasa un semáforo en rojo entonces
Por acá resulta que uno de estos textos era el que hablaba sobre la norma o sobre la ley de no pasar un semáforo en rojo y sobre la multa que que esto conlleva Entonces digamos que ese está ubicado, acá lo voy a poner aquí con este rojito, digamos que ese que estaba diciendo está ubicado por acá Aquí es donde dice Qué pasa si te pasa un semáforo en rojo aquí es donde dice la multa y aquí por aquí es donde dice, eh? Que no puedes pasarte Entonces cuando tú llegas y le haces una pregunta el modelo lo que hace es que también convierte este texto en un vector él convierte este texto que vos le estás preguntando en un vector y llega y lo ubica en el espacio Entonces cómo es un vector que está hablando de un semáforo en rojo, posiblemente en el espacio de este modelo de lenguaje. Esté ubicado aquí cierto. Ahora tú llegas y le indicas a tu a tu algoritmo, digámoslo así o a tu framework, Hey em estoy preguntando por esto quiero que me recuperes.
Los cinco vectores que más similaridad tienen al tema que yo estoy hablando entonces pues por por similaridades hace una operación hay varias maneras de hacer similaridad pero hay una Pues que normalmente se usa que es la similar por coseno o bueno hay una similaridad semántica entonces llega y te dice Ah bueno vea estos de acá son los cinco vectores que más se parecen a a lo que usted está preguntando entonces la arquitectura rac lo que hace recupero estos datos recupero los datos donde dice Cuál es la multa Cuál es el contexto, eh? Por qué no debes pasarte etcétera etcétera se los pasa completamente al lm o bueno tu modelo de lenguaje el modelo del lenguaje utiliza todo eso todo ese bloque como contexto Entonces lo utiliza esto esto esto esto esto y obviamente la pregunta lo utiliza como contexto y tú por medio de un Chrome tú le dices a tu a tu arquitectura rack em, Respóndeme la siguiente pregunta y aquí es donde pones la pregunta.
Con este contexto aquí es donde le pones el contexto y él te genera un resultado con eso Entonces los modelos de lenguaje básicos son como personas, pues yo siempre lo veo de esa manera son como personas que saben mucho, pues saben hablar y saben mucho de muchos temas tienen mucha información base Pero si tú quieres un tema específico, tú debes encaminar al modelo para que llegue a ese tema específico Entonces eso normalmente es lo que se hace con esta arquitectura de rack. Coges todos estos vectores que se generaron todos estos estos fragmentos de texto que se generaron se los das como contexto y pues ya el contexto, puede puede generar Eh pues puede hacer todo este de pues generar una respuesta coherente a veces Qué puede pasar estos estos esta arquitectura, pues no es perfecta tiene sus fallos, por ejemplo, puede ser que tú tengas un fragmento.
De texto muy grande, que tengas un fragmento de texto que sea muy grande en el cual digamos que estés hablando de de la multa con el semáforo en rojo Pues de todo el contexto de la multa y por aquí en otro pedazo de texto mucho más lejos es donde hablas de la cantidad de plata que tienes que pagar cuando cuando pasas un semáforo en rojo, entonces puede ser que por cosas de la vida porque están muy lejos de ese texto uno del otro en este texto de acá no se menciona en ningún momento que esa multa es exactamente para el semáforo en rojo Entonces cuando le haces la búsqueda por similaridad no le llega esta parte del texto al a tu a tu modelo de lenguaje y pues no se entrega una respuesta coherente. Eso puede pasar y y me ha pasado inclusive en en las soluciones que he hecho entonces no es perfecta, pero si es un buen acercamiento a evitar hacer el find tuning. Tú podrías hacerle fine tuning a esos modelos y agregarle to Data pero como les digo requiere una.
De cómputo importante y y pues que la Data hace muy bien etiquetada. Que esté muy bien hecha. Entonces la arquitectura rac es la que se usa para para este tipo de situaciones que son más comunes Entonces les voy a mostrar un poquito de Pues con con esta es una, pues una breve explicación obviamente hay muchas cosas que me dejen en el tintero, pues no, no digamos explicar esto a detalle, Eh Pues implicaría muchas sesiones Y esto es una sesión más bien como como básica para explicar unos conceptos básicos, eh? Pero les voy a mostrar un poquito de Bueno un poquito, nos vamos a dar el código de cómo funciona yo les dejo, pues el repositorio para que lo repliquen em en el ejercicio yo utilicé el modelo de llama de llama 3.1 de 8 billones de parámetros, pero es particularmente porque yo tengo un computador que que si tiene una gpu y puede correrla pero pues yo sé que no todo el mundo tiene ese tipo de de equipos. Entonces si quieren hacer ese tipo.
Puedes experimento en sus casas pues o en sus oficinas O donde quieran pueden utilizar modelos más pequeños como fin obviamente, pues los resultados pueden variar pero pero es un acercamiento o bueno, si tienen ya una suscripción a Open ella iba a Cloud o a grow o al que sea pueden utilizar esa Api también cierto, ya van a ver que en el en el framework, eh? Es muy fácil cambiar entre modelos Bueno entonces primero les voy a mostrar un poquito de eh, Como el flujo que va a ser el framework, que les tengo preparado y luego ahora sí se los muestro Entonces el flujo de este framework es vamos a utilizar una herramienta que se llama radio radio Es una herramienta que se utiliza para hacer demos de The Machine learning cierto. Tú también bien, podrías publicar algún producto en radio pero pues eso dependería de de cada uno cierto Normalmente se utiliza para para demos por qué.
Que pues genera una interfaz gráfica y te genera Pues un un es un link para que una URL para que lo puedas compartir Entonces ese proceso Cómo cómo empezaría vamos a tener una interfaz de usuario en esa interfaz de usuario, vamos a tener una entrada que es lo que va a consultar el usuario, pues la pregunta que el usuario va a hacer eso por medio de la interfaz de usuario, va a enviarme una solicitud al servidor que en este caso el servidor Pues voy a hacer yo, eh? Pues yo voy a tener el servidor corriendo ahorita se los muestro Se envía la consulta la consulta llega a algo que se llama red River o él como el recuperado que es básicamente, eh? La clase o la entidad que se encarga de Recuperar el texto para convertir la pregunta en un vector y ir y recuperarla entonces él viene hace búsqueda de los vectores más relevantes, eso lo hace aquí en la base de datos vectorial en para el caso del ejercicio, vamos a utilizar files está
Datos vectorial lo que hace es retornar la cantidad de vectores que yo quiera que me Pues que yo quiero que me retorne entonces me devuelve los documentos el retriever lo recibe y ya lo que hace es que invoca al lm generando pues, eh? El prom completo que tiene que hacer Entonces el con los documentos relevantes le pasa eso al dllm o al slm o al modelo de lenguaje. Cómo llamar para este caso va a ser gama 3.1 de 8 billones de parámetros él me genera una respuesta y me devuelve la respuesta a Pues a mi radio a mi al servidor y el servidor finalmente envía la respuesta al usuario Entonces eso es lo que vamos a a ver en un momento, eh? Yo les voy a compartir el link cuando monté el servidor Y ustedes le pueden hacer preguntas pero pues no sé, eh Cuántas solicitudes pueda recibir a la vez vamos a probarlo posiblemente se me estalle el PC y se me caiga el servidor pero lo vamos a ensayar Entonces ahora sí vamos al código entonces
Voy a cambiar de pantalla para que veamos el código completo un segundito listo. Aquí está. Bueno, voy a compartir pantalla nuevamente listo Bueno yo creo que ya estamos viendo Bueno entonces, cómo funciona Cómo funciona esto Entonces lo primero. Yo estoy utilizando wsl. Pues Por si alguno No lo conocía, pues mi computadora es Windows pero utilizo wsl para utilizar Linux porque estoy utilizando Linux y no lo hago directamente en Windows porque para utilizar la gpu em digamos que es un poquito más complicado utilizarla.
Windows porque hay que instalar algo que se llama kuda y qnn que son como unos drivers de nvidia para Pues de del fabricante la cpu para utilizarla y poder correr sus modelos y a veces, eh? Es complicadito entonces mientras que correrlo aquí directamente en en Linux es relativamente sencillo entonces tengo dos consolas una consola en esta consola voy a correr, eh? Me lm Cómo ven inclusive, ya había dejado código de una prueba y en esta otra consola voy a correr el servidor entonces Bueno lo primero que vamos a tener es este lo que ustedes van a encontrar en el repositorio que que yo les dejo esto este todo este código que tiene este código o qué es relevante que tenga primero que todo debe tener un un ambiente un archivo punto m, eh? Este archivo que trae el nombre del lm pues del modelo de lenguaje, que yo voy a utilizar Entonces en ese caso llama 3.1 de 8 billones de parámetros luego qué tiene el template del Chrome que voy a utilizar.
Claro, entonces para este template, eh? Utilicé esta esta frase como use las siguientes piezas de texto como contexto para responder la pregunta, al final hay un salto de línea si usted pues si no sabes, eh? La respuesta diga, pues no sé la respuesta. Ahí lo puse en español como para que él responda en español sí lo sabes, eh, mmm, Pues sí, sí, sí, sí, tienes la respuesta. Entonces hagan la haga una respuesta pequeña de tres o cuatro, eh? Frases O sea no, no eché mucho texto, no he hecho mucha carreta y le pasó si se fijan un contexto y le pasó una pregunta Entonces ya les vamos a dar el código En qué parte vas de contexto y en qué parte va esa pregunta finalmente aquí le digo como que Hey Déjenme la respuesta aquí y le pongo estos dos puntos para que el el modelo lenguaje empieza a generar de ahí en adelante Entonces como les digo el modelo de llama, No necesariamente es un modelo entrenado para chat es un modelo generador de texto, pero no.
Metes entrenado para chat entonces, por eso digamos que hay que hay que como controlarlo un poquito ahí Cómo ponerle riendas y ponerlo a trabajar entonces para la prueba, que les tengo preparado yo lo que hice fue prepare, eh? Una Data que es una Data que saqué Wikipedia o sea, literalmente me fui a Wikipedia y scrapie en la adapta de de la casa targaryen cierto. Entonces, pues es un PDF común y corriente, pues pero si se fijan es un PDF no escaneado cierto, es un PDF normal, eh? Generado digámoslo así por por Word o sea lo exporté si ustedes tuvieran en su compañía o donde quiera que lo estén utilizando PDF o o documento de texto que son imágenes o hay o están escaneados es muy probable que sea mucho más difícil de leer y les tengo que utilizar uno CR como tesera, o bueno, hay varios por ahí, pero el que me llegó la cabeza para extraer La información. Entonces, cómo funciona esto Bueno necesitamos entonces?
La variable las variables de entorno Ahí está Ah Me faltó explicar una variable más de aquí del archivo de variables de entorno que es la cantidad de vectores que voy a recuperar en este caso le estoy diciendo que me recupere 6 o sea, 6 fragmentos de texto, eso es lo que le estoy diciendo que que me recupere qué es lo que varía acá si yo me tomo o meto menos si yo le pongo más fragmentos de texto estoy haciendo el contexto más largo Entonces por ejemplo, si estoy utilizando la Pipe estoy metiéndole más tokens y esa Api cobra por tokens entonces, pues me va a salir más costoso cada procesamiento si yo le meto menos puede ser que no lleguen suficiente información para responder la pregunta o sea, para contexto de responder la pregunta y si usó exageradamente mucha información puede ser que se rompa la ventana de contexto, que yo tengo en mi modelo de lenguaje hay modelos de lenguaje actualmente pues, eh? El de Google que tiene una cantidad una ventana de contexto gigante pero pues
No, todos los modelos de lenguaje tiene ese tipo de de ventanas de contexto y pues puede salir más costoso, entonces también para que lo tengan en cuenta aquí como Pues yo lo estoy corriendo en mi máquina, pues va a ser gratis. Entonces, pues puse seis pero pero para que lo tengan en cuenta cierto, o sea, muchas veces poner más no es lo mejor listo Bueno entonces, qué es lo que tenemos Entonces tenemos una carpeta de Data aquí es donde estoy guardando mi PDF o mis PDF yo puedo priorizar muchos archivos en un solo índice y tengo un un archivo que se llama create Index Entonces qué es crear el índice lo que les explicaba hace un momento en el en el Paint que crear un índice es coger todo mi documento partirlo en pequeños fragmentos y convertir esos pequeños fragmentos de texto o el documento en en vectores cierto, entonces, pues para hacerlo rápido, pues cuando corro Esto es lo que hace es que revisa Cuáles son los documentos que tengo.
que pida, que me pide que escoge que escoja Perdón entre los documentos que tengo Cuál es el que voy a procesar Pues hagámoslo de una vez corramos lo para que lo vea python y creating es cuando yo lo corran me dice, ey bueno, Cuáles documentos, quieres procesar entonces puedo decirle que todos, o sea, Cómete todos los documentos que yo tengo y me los procesen un solo índice o pues procesa el índice por separado Cuál es la diferencia de esto digamos que si yo mezclo muchos temas en un solo índice hay temas que por mes Pues por la mezcla de palabras puede ser que digamos que yo tengo la información de la casa tergiversa y la información de la familiar real inglesa, entonces habrán muchas palabras parecidas entre esos datos Entonces yo lo mezclo todo en un solo índice cuando yo le pregunté y quién es el primer rey Entonces se me va a recuperar texto por
De Quién fue el primer rey de la familia real inglesa y quién fue el primer rey de la casa targaryen que es si no saben la familia de de los targaryen de Juego de tronos o de la casa del dragón. Entonces, por eso es una buena práctica a veces, eh, hacer los índices que sean separados por temáticas, pero pues no siempre lo mejor pero, eh? A veces es bueno cierto Entonces si hay temáticas que son muy muy parecidas entre sí paralelas, si son temas muy distintos Y pues la empresa o el problema lo requiere, hágalo, junto Entonces en ese caso, pues bueno, yo, eh? Yo ya no había procesado, pero básicamente ahí, simplemente le doy uno Ahí está le doy enter Y pues sí, me va a empezar a procesar, no lo voy a procesar en este momento porque se demora, pero básicamente qué es lo que hace esto Entonces es lo que hace es crear es es correr este esta función que se llama room, eh? Create Index lo llama todo está con solita listo ahí corre esta función.
Corre esa función Perdón se llama Run create Index esa función que hace esta función, vean aquí está dentro de dentro del mismo archivo Entonces esta función, lo que hace es que instancia esta clase que se llama Index manager service y este Index repositorio, Qué tienen las clases service si han trabajado en desarrollo alguna vez, pues eh, Hay una arquitectura que se llama hexagonal lo que hace es que divide em digamos las funcionalidades en bueno, eso se llama principio sólido divide las cosas en responsabilidades, cierto, yo he vivido Mi código por responsabilidades Entonces qué es lo que normalmente es la responsabilidad de las clases de tipos Services las clases de tipo service lo que hacen es invocar funcionalidades específicas Pero ellos son los que tienen la lógica por dentro, no voy a eh, entrar mucho en ese tema porque es un tema más de más desarrollo, pero estás clases de tipo ind.
En este caso está Index manager, pues simplemente lo que haces Llamar los métodos que tiene mi repositorio, entonces me tengo crear el método guardar el método cargar borrar. Date es muy de desarrollo, Pues esta parte, pues no voy a entrar mucho a detalle, pero igual lo pueden revisar en el código por si quieren digamos que el grueso de esto está en la clase, Eh Pues de tipo repositorio cierto, entonces normalmente las claves de tipo repositorio es donde sí está que Conectarme a la base de datos se Conectarme a una Api en específico etcétera entonces Bueno qué es lo que hace esta clase? Pues lo que hace es que instancia, eh? Instancia a a mi base de datos vectorial en este caso a files, entonces aquí lo que hace es bueno empieza carga el PDF lo carga como una instancia de de Five utiliza en vanes, en este caso estoy utilizando los envase de hugging Face pues que yo.
Muchos la conocen es una plataforma en la que hay muchos modelos, se pueden utilizar gratuitos hago split de documentos utilizando los envase, o sea un split por contexto género mi instancia, eh? Vectorial, o sea, cojo todos esos fragmenti texto. Eso eso esos fragmentos se generan aquí en este split para No pues entrar mucho detalle y aquí ya género, mi vector, o sea, mi base de datos vectorial o mi índice Cómo se le suele decir y ya pues aquí lo cargo, lo lo guardo en local Entonces por ejemplo, cuando estamos trabajando en en ashure o en aws Pues aquí lo que hacemos Es que guardamos esto en un Data Lake en un blog Store Ash o en un S3 Bucket en el almacenamiento que nosotros queramos cierto, pues lo guardamos en local y ahí lo tiramos para el almacenamiento de esa manera lo podemos invocar en cualquier momento Listo entonces básicamente eso es lo que hace crear el índice.
El índice lo guarda Y esto es un índice o así quedan en files como les digo cualquier, eh? Cada base de datos vectorial. Lo manejará distinto, pero file lo que queda así queda como una carpetita Pues con el nombre, que yo que uno le haya querido poner en este caso. Yo le puse targaryen Index y siempre me queda un archivo punto fais que es como el archivo de la meta Data y un picole un archivo, eh? De esos comprimidos con los que a veces guardamos los modelos de de Machine learning. Eso es mi índice. Entonces ahí están guardados mis vectores de n dimensiones Cuántos pues no estoy seguro, entonces así funciona. Entonces este este código es relativamente sencillo de ejecutar Aquí están los recuerdos Entonces si lo van a utilizar en su casa, entonces simplemente llegan clona el repositorio instalan la paquetería En un ambiente crear un ambiente está en una paquetería Crea una carpeta Data porque pues ahí en el en el repositorio no la van a ver, pues yo no la subo directamente dentro.
Carpeta Data ingresan todos los archivos que ustedes quieran procesar y Ejecutan el el programa pues python y el nombre del de la función, pues del archivo Perdón le dicen que quieren indexar y ya les se les genera el índice Entonces ese índice ya lo podemos cargar en cualquier momento Entonces lo vamos a cargar en este momento Entonces para cargarlo aquí. Yo tengo otra pequeña función cita que se llama, eh? Que se llama Life c. Main Main Jack Entonces qué hace la función Main Esta es la que me va a levantar todo mi servidor entonces para levantarme mi servidor Pues aquí está la ejecución yo Cargo en ambiente virtual cargo mi carpeta, Dónde están los índices escojo Cuál es el índice que quiero ejecutar creó el Red River eh crear el que es crear el Red River es como decirle a a mi modelo, vea, va a utilizar, vas a utilizar?
O sea, datos vectorial vas a utilizar este prompt y lo vas a ordenar de esta manera, no voy a entrar a a mostrarlo ventilación. Tenemos que firmar Aquí está create River Ahí está llamando Pues mis mis variables de entorno, Pues en el archivo cargo el Index manager, pues mi instancia y una instancia de la Chain manager service entonces que el ingreso el ingreso el nombre de mi modelo lm le ingreso, eh? El vector que voy a utilizar cierto, o sea, me hace datos vectorial, le ingreso mi Pro le ingreso, eh? Y cuál es la Chain que un segundo que mi hermano está por acá problemas técnicos muchachos, pero creo que va bastante bien, no sé si tienen dudas igual saben que pueden abrir micrófono.
Cuando quieran lo explicó súper claro, me sirvió muchísimo Esta es la base con la que está funcionando o con la que se está construyendo, pues como este asistente virtual ya ahí ahí los están teniendo cuidado a ver qué pena regrese, mi hermano llegó y estaba pidiendo que le abrí la puerta Bueno entonces Eh me perdí donde yo Ah sí, listo estaba creando El el cómo cómo funcionaba. Entonces creo finalmente la el Chrome creó la cadena. Les voy a mostrar un poquito de cómo se crea la cadena, pero no les voy a mostrar, les voy a explicar cada detalle del del código porque sé que es confuso O sea si lo ven así como muy por encima, eh? El código es confuso. Entonces, eh? Igual Se los voy a mostrar, qué es lo que hace entonces este código entonces este código lo que hace es primero cargar el el modelo lm entonces para cargar el modelo lm o mi modelo de lenguaje yo utilizo.
Que se llama o llama o llama? Yo creo que de pronto la han escuchado por ahí es una librería que me permite trabajar con diversos modelos de lenguaje en local o Pues en un Home Premium en un servidor donde yo tenga Pues un una gpu este o llama entonces Eh pues ustedes la descargan es pueden ir a a Google o Descargar gratuito y descargan el modelo que van a utilizar entonces por eso instancia o llama Y pues le decimos Cuál es el nombre del modelo que vamos a utilizar aquí, por ejemplo es donde ustedes podrían variar Entonces si no quieren utilizar un modelo en local, sino que quieren utilizarla rápido pdi, pues aquí instancia no pene hay, eh? Pondrían Cuál es su clave, pues su Api key Sur su modelo, etcétera cierto, el el requiere, pues unos unos parámetros Ahí es donde lo ingresarían O si quieren utilizar Cloud O si quieren utilizar clock o si quieren utilizar Bueno cualquier, eh? Cualquier cualquier modelo de los que están disponibles cierto.
Entonces aquí le estamos diciendo que la búsqueda que vamos a hacer es de tipo similaridad, vamos a hacer una búsqueda por similar ya, pero hay varios tipos de de búsquedas. Estamos diciendo Cuál es la cantidad de de vectores, que quiero que me recupere, pero estamos diciendo que me recupere K vectores que sí sé si se acuerdan en las variables de entornos, yo había ingresado 6, entonces ahí lo pueden cambiar ustedes como quieran aquí creamos la cadena con el Chrome que les mostré, eh? Que es un Pro Pues él, el que está aquí en la variable, entorno, este de acá. Ahí se crea la la cadena con esto y se fijan en este Pro al final al final al final al final está el contexto y está la pregunta que se va a hacer entonces ese contexto Y esa pregunta, o sea, todos los vectores que yo recupere, o sea, toda la Data que yo recupere la voy a meter en esta variable, que dice contexto y aquí va a ir la pregunta ahorita les muestro cómo queda al final Pues todo, pues todo organizado listo.
Dice crea Pues el Chrome le estoy diciendo que a Jenny me lo den donde dice contex, ahí está. Ahí está aquí está bueno, esa ese ese partido del código, eh? Estoy utilizando también un framework, que es probable que lo hayan escuchado que se llama lang Chain su framework, pues hecho por la comunidad para para trabajar con todo este tema del lm de una manera un poco más sencilla, que a veces complica las cosas, pero también, eh? Ayuda mucho en ciertas situaciones. Entonces ya les voy a mostrar un poquito más cerca Bueno entonces ya finalmente después de haber creado todo mi todo mi mi retriever o o el que se va a encargar de recuperar los datos. Yo lo retorno lo retorno aquí en esta se llama Cuba en esta área que se llama Cuba y aquí lo que hago es montar la interfaz de radio. Entonces simplemente le digo radio trabaje como una chat interface, pues una interfaz de tipo chat y cada vez que te hagan una pregunta.
Llamas esta función que se llama responde que aquí está, que básicamente Qué es llevamos mi retriever, le pasó mi pregunta y obtengo el resultado es eso no es más y pues aquí son unos parámetros Pues de de radio, que ya lo van a ver entonces voy a ejecutar este este código y les voy a eh, pasar la URL para que puedan inclusive ustedes hacerle pregunta. Entonces aquí, qué es lo que estoy haciendo levantando Eh mi servicio, entonces él me está preguntando Ey cuál índice querés trabajar como en este caso solamente tengo uno, pues se lo ingreso. Entonces ahí está ahí lo empieza a montar Pero entonces, qué va a pasar en este momento, eh, Aunque esté corriendo o empieza a correr el servidor no va a retornar respuestas por qué? Porque yo todavía no he empezado a correr mi modelo lm Entonces se fijan aquí ya me llegó la URL se las voy a compartir.
Puede abrir esto y y hacer preguntas entonces Déjenme yo la comparto aquí al chat, aquí estamos listo. Eso queda eso queda Life por eso es es bueno para hacer pruebas de concepto porque vos llegas con esto Live y se lo puedes mostrar a un cliente etcétera, entonces podemos si alguien hace una pregunta en este momento Pues yo puedo entrar yo mismo si hago una una pregunta en este momento, eh? Va a fallar, o sea, va a quedar ahí pensando y va a fallar, es una interfaz relativamente sencilla porque no he aprendido todavía mi modelo de lenguaje. Ahí está él me dice estoy en en targaryen, targaryen Index y soy una una de tipo chat y aquí escribo la pregunta, no me mande todavía ninguna pregunta porque va a fallar Ah Bueno de hecho, ya veo que alguien. Mandó una pregunta. Veo que alguien mandó una pregunta y qué preguntó esa persona preguntó Cómo se llama el dragón más grande alguien hizo esa pregunta, no va a llegar ninguna respuesta.
Lo que les digo no tengo todavía encendido el modelo lm Pero entonces vamos a encenderlo entonces para eso tengo aquí mi otro mi otra consola Entonces como ya estoy aquí entonces yo hago o llama list, eso me va a listar todos los modelos LLL que tengo pues que tengo en en mi yamama démosle un segundito que mi máquina está full. Entonces vemos que hay tengo el lo llama 3.1 de 8 billones de parámetros, pues vamos a activarlo o llama Run llama 3.1 dos puntos Ups 3.1, dos puntos ocho billones, ahí empieza a encender y me recurso empiezan a drenarse.
Eso es mi recurso Entonces como ven esto empieza a comer muchos muchos recursos, eh? Porque son modelos grandes Entonces ya se imaginarán, pues como son las máquinas que tiene Open ella y o las máquinas que tiene cualquiera de estas, eh? Empresas que eh, manejan El lms Bueno entonces Ah De hecho vemos que ya entregó la respuesta, Qué le respondió la persona que hizo esa respuesta Esa esa pregunta Bueno ahí llegó otro cómo se llama la mano de realidad targaryen traigo la respuesta Bueno entonces les voy a explicar, no, no hagan más preguntas por el momento ahí llegó otra, no, no más que más preguntas por el momento porque quiero explicar cómo funciona lo que se está construyendo aquí. Entonces si ustedes se fijan aquí en la consola También estamos usando en verde, eh? Toda la cadena que Se generó.
Dentro de mí dentro de mí algoritmo cierto, entonces vean aquí está el Chrome Recuerden el prom que yo puse al principio use las siguientes piezas de de este contexto para responder la pregunta al final si no sabes la respuesta, por favor, digan no sé la respuesta, eh, No se ponga a inventar cierto mantenga la recetas pequeñas limitadas, No no es muy grande, pues no, no haga algo muy grande, entonces mira que ahí ahí empieza Pues aquí era donde estaba el corchetes recuerdan Ahí están los corchetes entonces mira cuando están los corchetes él empieza a meter todo el contexto que encontró entonces todo esto que ven acá de aquí de aquí es una pieza de texto que él encontró y me dice Cuál fue Eh Pues cuál fue la fuente en este caso solamente hay una fuente pero pero hay muchas Fuentes Pues tú puedes poner muchas Fuentes en en un solo índice aquí otra, pues Recuerden que yo puse seis entonces aquí está la otra vea, otra pieza de texto dos aquí hay otra Esta es más grande tres.
Es el que dice editar es porque lo saqué de Wikipedia cuatro cinco seis reciben seis piezas de contexto, qué tan grandes van a ser las tiras de contexto dependiendo cierto en este caso yo utilicé, eh? Hugging Face y le dije que me hicieras split a mi documento por contextos O sea pues como que el más o menos sepa dónde hacer los split, pero yo puedo hacer los split por número de tokens, puedo hacer los split por eh, cada vez que haya un salto de línea puede explicar? Es que haya un punto seguido que haya dos puntos yo lo puedo definir como quiera lo que normalmente se ve en tutoriales o en o muchas veces encuentras en la industria es que la gente hace split por número de palabras, cómo queda cada 1000 palabras pum, hágame un split cada 1500 palabras pum acá en split y hágame algo que se llama Eh pues como superposición de texto para que se sepa que un texto se combina con otro, eh? Eso hay muchas maneras de hacer el Split y dependiendo también, cómo se haga el Split van a hacer las respuestas cierto.
Mira, ahí está el contexto y al final del contexto está la pregunta Aquí está question. Ahí está la pregunta y luego yo le pongo como que aquí Ponme la respuesta y eso es lo que él envía entonces por eso aquí dice como Finish shein, listo, muchas veces las respuestas Dependiendo el modelo van a ser mejores que otras y dependiendo de los vectores que yo le haya ingresado Por ejemplo, si utilizo el modelo más poderoso pnea y posiblemente las respuestas casi siempre acierten, pero si yo utilizo un modelo pequeño, pues me respuestas, pueden ser mucho más discretas. Entonces voy a poner Aquí también una pregunta por si por sí Ay no lo tengo aquí por si nosotros lo han visto cómo funciona Entonces yo aquí le puedo preguntar. Es que no sé muy bien Cómo escribir los nombres a ver quién fue aegon dar hay media ha llegado.
Ahí me llegó, Quién fue icon targaryen. Entonces Él llega a la pues me llega la pregunta el con pues construye toda la cadena todo el contexto y le dice al lm pues le o a mi modelo de lenguaje Ey respóndame esta vuelta que que aquí tengo todo para que me responda y él ya me genera entonces aquí me dijo a ver el príncipe, voy a contar Gary es el primer hijo, el único balón del príncipe reggaetón y la princesa Elia Martell bla bla bla bla bla bla bla bla bla. Bueno, habría que entrar Pues a revisar porque hay como 10 segundos targaryen distintos en en en ese libro y pues también depende mucho de la Data como pues saben en tanto en los modelos lm como en cualquier otro tipo de modelos, si yo le meto basura, pero él me va a generar basura Entonces cuando se entra dando con la Data de sus empresas o de sus clientes o de lo que sea o de lo que quieran trabajar hagan esa depuración hagan una depuración de de de cómo estoy Desde qué edad estoy ingresando cierto es Data que que
Me está, no sé, está la que se generó de chats, por ejemplo de chats entre entre colaboradores o ataques de género de de resolver casos de una mesa de ayuda miren bien, cómo se Pues antes de de de de hacer toda esa infraestructura Cómo está la Data Ese es esto, eso es, eh? Muchachos lo que lo que genera o eso es la la infraestructura es una infraestructura, eh? Que se se utiliza mucho en el medio van a encontrar, no solamente se utiliza para chat. Digamos que ese es la más básica o la más normal que uno suele encontrar Pero esto no solamente se utiliza para chats también se puede utilizar para no sé, necesito extraer información de un documento. Entonces aquí le pasa O sea necesito, no sé eh? Construir un un json Entonces le pasó mi información toda mi información y le digo al final Construye un json de tal manera inclusive. Yo lo puedo correr acá Aquí está corriendo mi modelo. Yo lo puedo correr acá y le puedo decir, eh?
No sé responde Dime el sentimiento de esta frase Necesito que Estoy construyendo es un pro de esta frase me duele el estómago Voy a poner de nada y aquí le digo responde en json de la siguiente manera sentimiento a borrar el Ah no ahí está sentimiento, vamos a ver Ahí está entonces mira que yo generé un Chrome y le dije Hey respóndame de esta manera, por ejemplo en este prom de los targaryen que yo acabé poner acá lo pude haber puesto ahí. Respóndeme la pregunta que está haciendo el usuario de la siguiente.
Pregunta y en un json, pues es un ejemplo pero pues le puedo decir que me lo responda en una cuerda y sql, o sea, hagan un acuerdo sql y Estas son las Digamos si tengo una tabla O tengo un esquema de sql de la siguiente manera y le pasó las tablas, le digo las llaves, se relacionan como entre ellas mismas y al final le digo Hey Necesito saber quién fue el trabajador más productivo de la empresa en el año 2023 Entonces como él ya tiene como contexto toda, eh? La construcción de de de tu cuerpo y pues de tu tabla de sql, pues genera un acuarela, eso eso es muy útil y por eso, eh? Se utiliza, pues este tipo de arquitecturas y bueno Y como tal este este tipo de modelos, LLL listo muchachos, no, eso es lo que les voy a mostrar por por el día de hoy, pues traté de ser muy muy acorde Pues con el tiempo, eh? Sí pues como preguntas en este momento, hágale, Bueno ahora, el servidor abierto, pues para que le hagan preguntas Mientras tanto, pero
Y me dicen los que le han estado haciendo preguntas, dicen qué tal esa ha respondido nadie preguntaron otra Cómo se llama el dragón más grande que de Juego de tronos Bueno ahí va otro Cuál es el origen de la familia targaryen y me parece me sigue pareciendo genial, eso que ya lo había visto porque como que le metes tu contexto, creo que eso es la Barrera más chévere, le puedes a personalizar a un tema que quieras y a pesar de que es un tema que sigue bomba no entiende porque yo preguntaría qué límites has encontrado que pueda tener eso no el primer límite que pues pueden tener estos modelos es la Data comienza construida cierto Recuerden que si yo le meto pues como les decía se le meto basura, Pues él me va a generar basura por más buen modelo que sea entonces si mi Data no está.
Bien, estructurada no es no es no tiene buena calidad cierto, tenemos que yo quiero utilizar los manuales de procesos de mi empresa para que cuando la gente le pregunté cómo hago tal proceso. Él te responda efectivamente cómo está el proceso, pero si tus manuales no tienen buena calidad, digamos que solamente son imágenes y como saben estos modelos de texto, Eh pues no me va a generar el resultado o los splits no los hice con conciencia, sino que lo hice así a la a la a la berraca Entonces no me va a generar buenos resultados Entonces ese es el el primer el primer problema que pueden tener y el otro problema Pues que que, que pues le he encontrado, es que sin también nos hacen con conciencia con un verdadero conocimiento a veces pueden resultar costosos O sea la gente abusa de ellos y pueden generar costos que usted no se imagina con esa correr algo que está muy grande, no te diste cuenta y cuando menos piensas tan tienes $50 de de 16.
Dólares de deuda Pues en tu en tu nube la que sea cierto entonces Esas son como como problemáticas que tienen pues y correr el local no es fácil, pues no es barato, No sé si alguien más me preguntas chicos Pero igual pues ahí tienen el repositorio muchachos es relativamente fácil de ejecutar, eh? Y si lo Ejecutan y y algo no les funciona me pueden escribir no hay ningún problema yo les yo les ayudo Pues también el el código traté de hacer pues relativamente fácil de entender es un framework, eh? Es fácil de utilizar si se fijan no se llevan muchas pues no se llaman muchas, eh? Funciones y las que funcionan Pues las que llaman Son son sencillas otra manera que pueden hacer para para entenderlo en el caso de que pues quieran entender un poquito más profundidad le pasan la función a chat de PT utilizando el lm.
Ya que se los expliqué, pero pero relativamente fácil de entender la banda levantada me escuchan bien Sí sí de uno perfecto Eh Al inicio mencionaste, pues que no podía almacenar esa información en bases de datos vectoriales. Entonces básicamente lo que les daríamos serían los índices, estaríamos almacenando los índices de una Y de pronto, tienes ejemplos por ahí con integrándolos con estas bases de datos un baby o algo así sí, claro, tengo un ejemplo pero es corporativo Entonces si quieres Más bien, me preguntas por Pues por como por privado y te muestro sin pues sin Mostrar O sea que lo muestro sin, eh? Omitiendo ciertas cosas, pero sí sí, sí, te pues no, no puedo dejar, pues como acá, pero sí, básicamente te cuento cómo funciona cuando tú haces una mongo de bit, Tú sabes que uno también genera como QR y Simón cierto.
Diferentes en los cuales dql Pero tú haces el mango divi Entonces cuando tú ves tú haces esas cosas de mango de vivir pues lo que haces es que generas un pues mejor dicho cuando almacenas un json en mongo Pues que es lo que almacenas el mundo divino tú le ves tú pones muchos ítems, pues que es como toda la metatah, que quieres almacenar y en una de esas metas pones el vector entonces tú pones vector y ahí pones tú pues como si fuera una lista o simplemente un vector de 2400 dimensiones o n cantidad de dimensiones cierto Cada lm pues puede tener sus dimensiones de 20 y básicamente Cómo construir la cuerina de mongo, simplemente le dices Búscame por búsqueda por coseno estás utilizando esta variable dentro de cada uno de los de los objetos de hongo, que es el vector te lo digo te lo puedo mostrar pero me me escribes como por privado para No mostrarlo pues aquí en como a todo cierto pues corporativo Gracias listo.
Lo único Ah bueno, eh? Con respecto a las a las bases de datos vectoriales, por qué estoy utilizando la de Five o la de Facebook Esta es gratuita es como saben meta bueno Facebook es meta cierto, ha tratado de de trabajar de manera Open source, estos estos temas de de Inteligencia artificial pythor, que es la librería de Deep learning de de meta es gratuita. Eso pensó esta base de datos vectorial inclusive. Llama este modelo que yo estoy utilizando es el de meta y es un modelo gratuito entonces, por eso pensó source. Entonces, pues como ellos están consumiendo todo ese ecosistema Esa es la base de datos vectorial de ellos que la puedes, o sea, este resultado lo que él genera como les mostraba era Era este ese archivo de metatah y este y ese people eso tú lo puedes generar en un Data led, pero lo puedes guardar en un Data Lake lo puedes guardar en un ware en Warehouse lo puedes guardar en un S3 Boxer en profesora?
Un Eh firebat, bueno se llama Fireball de Google no me acuerdo, pero sí hacen un Google Drive lo puedes guardar y ahí lo consumes Entonces eso es lo bueno de este tipo de de de bases de datos vectoriales no tienes que montar todo un servidor, por ejemplo como como en psicoac o un servidor de hongo y no tienes que correrlo para poder consumir esas esas bases de datos vectoriales, sino que simplemente ese archivo pico ya creo que Jonathan también tiene una pregunta. Cuéntalo, sí, Juli Cómo estás bien. Yo te quiero hacer una pregunta con respecto a lo que estabas hablando y de los vectores Eh bueno yo actualmente también como te había comentado hace editas, estoy trabajando, pues con un modelo un poco ambicioso pero eh? Logré pues hacer una conexión con asturo penal y el azul cogniti Search Sí y eso pues para hacer pruebas de entrenamiento con PDF funcionó muy bien.
Podemos mencionaste que debía de hacer el entrenamiento del esquema de la base de datos es que voy a trabajar, pero no he podido Cómo llegar al punto de Cómo debo yo, eh? Agregar o cómo debo de de entrenar el modelo con con este esquema Cómo se lo voy a entregar listo bueno de una entonces, pues partamos desde la idea de que en en realidad Cuando tú haces está arquitectura de rac, no estás entrenando el modelo cierto, o sea el modelo no está, no está cambiando sus parámetros Pues digamos que cuando utilizamos el el término de entrenar es porque vamos a cambiarle las los pesos al modelo, pero en este caso no, no lo vamos a hacer sino que simplemente le estamos generando los vectores para trabajar, cómo o o o el cómo le vas a ingresar la Data eh? El esquema de tu base de datos hay varias maneras cierto, pero pues lo normal es que cuando tú abres un gestor de de psicoanálisis en el caso de que lo tengas en en en sql, tú puedes darle Cómo generar.
Cierto Entonces él te dice como que voy a hacer aquí algo rápido en en este chat, eh? Como si fuera una tabla pequeñita Entonces como algo así como tienes una tabla de sql con las siguientes con el siguiente esquema con el siguiente esquema Entonces qué le digo como que tabla uno, eh? Digamos tabla uno punto llamémosla Index o índice indies voy a poner solamente dos datos índice nombre índice contiene el índice del empleado digamos que es una tabla de empleados digamos que tiene nombre contiene el nombre.
Del empleado y digamos que tiene horas trabajadas horas trabajo horas trabajadas y contiene las horas trabajadas del empleado, así lo hice pues muy básico Pero la idea es que tú lo montes en en un json bien bacano bien, chévere cierto y digamos que uno aquí le quiere decir genera una query de sql para indicar. Quién es el trabajador más, no, el trabajador que más horas ha trabajado Bueno aquí en realidad no le dije Cuál es el nombre de la tabla. Entonces digámosle también Cuál es el nombre de la tabla Ah Bueno en realidad, sí le dije que es tabla 1 pero le voy a poner un guión bajo porque esto con espacio se ve muy feo, entonces mira que tú en el Chrome estás generando.
El esquema de la tabla tabla 1 y digámoslo así vamos a mirar si me me genera genera una cuerda sql Así vamos a ver qué me genera listo Entonces entonces si se fijan ahí me generó una consulta sql. Yo le pude haber dicho que solamente me entregue el sql o que me entregue un json con el sql para para hacerlo digamos de una mejor manera entonces miran que él está diciendo listo, vas a generar un Select de nombre que es, eh? La columna sí.
columna, Dónde está el nombre del empleado de dónde de la tabla número uno que es la tabla que yo le acabé de ingresar y que me le haga un order by por horas trabajadas que es la columna donde yo estoy ingresando las horas que trabajo que lo haga de orden descendiente y que en orden descendente y que me entregue solamente el primer dato entonces mira que ahí él ya me está generando una ya yo tengo que entrar a manipular lo que él me está generando Por ejemplo yo en ese mismo Chrome yo le pude haber dicho que me genere un json con la respuesta yo le puedo decir incluida acá genera un json con la respuesta de la siguiente manera los puntos vamos a ver si me lo genera así un poquito más alto vez este Rebelde Ah bueno le tuve que haber dicho en realidad que me generará solamente el
el Jason sin nada más Pero bueno también este modelo, pues no es el el más poderoso, o sea, es todo un modelo pne es muy probable que que te lo saqué mucho más fácil, pero entonces mira que cuando él te lo genera Así ya tú lo que haces es extraer ese json, Pues con python y inyectar esa QR y en el org que vos tengas para consumir la base de datos, el que estés utilizando y cuando tú lo inyectas Ahí ya te genera una respuesta que normalmente es una dupla, ya tú puedes a tupla y la procesas en python o o en lo que estés trabajando, pues normalmente python Y pues el resultado obviamente esto es una es una tabla que me acaba de inventar es una nota la que no es real y es un índice es un esquema muy sencillo, pero básicamente todo lo todo esto que está que estás viendo en verde, sería como el esquema cuando tú generes esa conexión a las bases de datos Entonces él te va a llegar y todo eso que va a salir en verde va a
Como que Ah bueno, tabla 1 columna tal columna tal columna tal una explicación de lo que tiene la columna y con qué conecta Esa es la llave principal o es una llave foránea lo que sea y aquí la otra tabla con la que desconecta y aquí otra tabla con la que conecta porque sabemos que un esquema de de una buena base de datos va a tener muchas tablas entonces así todo esto va a ser lo vas a generar como contexto y al final la pregunta, va a ser Hey Quién es el empleado, entregamos un un json con con la cuera y para sacar. Quién es el empleaba más productivo. Eso es eso es básicamente no sé si respondí tu pregunta Jonathan igual, lo podemos revisar un poquito más a detalle listo Julio Muchas gracias, mijo al papa, carísimo, Dale Hola escúchame ahí cierto. Yo tengo una preguntita, eh? Ahí cuando me estás diciendo pues.
Los índices podríamos decir que es como lo que es experto en este momento cada así es cada Cómo se llama o cada cosa que le voy a decir sí Y entonces ahí el tema con el promin Jenni ring, Cómo podría jugar ahí o cómo o cómo o cuál es el papel ahí con este listo veamos de la siguiente manera. El Pro mentira es las riendas que tú le vas a poner a tu modelo de lenguaje, o sea, tu modelo de lenguaje, eh? Es un imán o míralo así como una persona que sabes escribir sabe pues sabe Mucho de muchos temas básicos cierto, es muy básico muchos temas Entonces el Pro men Junior es las riendas que tú le vas a poner O sea tú le das a a decir, o sea, todo esto todo esto que ves acá es el Chrome todo eso que estás haciendo acá es el Chrome entonces, tú le estás diciendo vea, señor l, pues modelo de lenguaje más a responder de la siguiente manera.
Actuar como si fueras un asistente de ventas o eres un experto generando query entonces ahí tú le empiezas a cómo a ensillar le pones las riendas le pones todo y lo montas y todo este índice es el contexto es el conocimiento que le estás dando entonces con el problema engineering tú lo en sillas y le le das conocimiento y le dices vea usted hace un experto en no sé medicina Entonces yo podría tener un un un índice aquí gigante de temas de Medicina Entonces el modelo de base es muy probable que en su base en su entrenamiento es más más interno él tenga un poquito de nociones de Medicina pero él no va a ser experto en en en un tema en particular Mientras que el índice le va a dar toda esa experticia en el tema que vos necesites y el provenir lo va a hacer Que responda a la manera que vos quieras. Entonces, qué haces en el propio Junior y le dicen listo Entonces usted va a actuar como un doctor experto en anestesia cierto una anes.
Vas a actuar como un doctor experto anestesiólogo, vas a responder de la siguiente manera Entonces le dices que que va a responder cordialmente o que va a responder, eh, Muy jovial, eh? Le dices que tú la respuesta la va a dar en no sé en tres en tres párrafos en un párrafo, que al final de la respuesta va a responder con un con Pues con un diagnóstico etcétera y luego le pasas todo ese contexto, que es lo que es el índice Entonces si el provenir es muy importante, Por ejemplo, en el en el ejemplo anterior que estaba haciendo en el tema de las de las cuerdas, sql. Yo le puedo decir Hey Mirá vos sos un un experto en general juveniles de sql cierto. Ese es tu función en la vida generar sql y entregar y y y la respuesta que vas a la pregunta que te voy a hacer simplemente una cuerda sql sin más sin está sin estos punticos sin la sin esto sin nada, solamente va a entregar una cuerda sql y ya.
Y ahí sí le entregas todo el contexto, le entregas la pregunta y y él ya si te va a responder de esa manera Entonces es muy importante eso del del proveni, eh, Hay muchas técnicas, por ejemplo, hace hace Eh Pues creo que fue a principio de año el año pasado no recuerdo bien, se había popularizado mucho una técnica que pues le hicieron papers y toda la vaina que era decirle al modelo como que eh ofrecerle propina al modelo entonces decirle como vea piense antes de responder piense paso a paso tranquilamente y te voy a dar una propina si la respuesta es buena y el modelo que hacía pues entregaba una mejor Respuesta Por qué, pues posiblemente en su Data de entrenamiento, eh? En alguna parte mencionaba que los meseros o que la gente trabajaba mejor si le daban una propina o algo así entonces, eh? Él trabaja de esa manera Entonces es muy bacano, el tema de provin y de hecho como con Trump pues compró.
Screen se hace también una metodología que se utiliza actualmente en en agentes que llama una metodología que se llama react, cómo reaccionar actuar y básicamente hace que es como la combinación de varios modelos. Entonces hay un modelo que es como el cerebro y ese modelo hace como todo esto que vemos en verdecito hace como raciocinio de Cómo resolver un problema Entonces le preguntan sobre ella, eh? Quién ganó el Super Bowl de 1992 entonces Él llega y empieza pues hacer un raciocinio y dice como Ah bueno para saber eso te voy a consultarlo primero Pues que ese Super Bowl obviamente. Él sabe que es el Super Bowl Pero digámoslo entonces va Wikipedia tiene una función para ir a Wikipedia y consulta que es el Super Bowl Ah listo, ahora consulto quién lo quién lo ganó en tal año ya recibe el dato y o sea, va haciendo ración racionalizando sería racionando, no? Bueno empieza a pensar y
Y a mirar Cómo resolver el problema obviamente eso no se puede hacer con modelos pequeños, o sea, es como puros modelos grandes que que tiene esa capacidad de de hacer eso, pero eso es pura provenir, o sea, es Problem y más Problem Entonces es es bacano cuando estén haciendo este tipo de de arquitecturas, eh? Es bueno que le peguen una estudia yita a Cuáles son los mejores Pro para para el problema, que ustedes están trabajando en específico. Bueno, muchachos más preguntas súper bien, entonces tienen más muchachos de una de una de pronto, no sé si lo explicaron al principio, pues pero porque yo no no está en ese momento y es el contexto de la de por ejemplo de la conversación cierto, está cómo se va a almacenando al mismo contexto, que que le estoy dando para entender para seguir entendiendo que está en el mismo contexto listo.
Bueno entonces básicamente en por ejemplo en este caso de uso que yo estoy haciendo si se fijan cada vez que ustedes hacen una pregunta, él vuelve y genera todo ese texto en verde cierto todo esto O sea desde acá hasta acá él lo está generando todo, pero él no está guardando, eh? La conversación, o sea no está guardando datos anteriores de la conversación o sea sí, yo le pregunto aquí no sé, digamos que este que este chat que tengo aquí le vuelvo a preguntar otra cosa sobre Hey no quiero que me hables de exactamente de esto de un cuarto él no va a tener todo este contexto acá porque yo no lo estoy almacenando el contexto Entonces qué es almacenar el contexto algunos frameworks como este como lancha tiene algunas librerías para esto pero pues tú lo podrías almacenar e inclusive en una base de datos común y corriente cuando tú almacenas el contexto para que él siga Sabiendo Cómo va la conversación estás aumentando tu ventana o la ventana que tiene el modelo de de todo.
Eso este digamos que es llama 88 billones de lodo tiene 14 tiene como 14000 tokens de contexto quiere decir que yo puedo ir guardando la conversación Por 14000 tokens cierto Entonces digamos que mi primera mi primera pregunta fue esto y él me dio está respuesta es de Cachito de acá, entonces para la siguiente pregunta que yo voy a hacer, le tengo que ingresar también todo este contexto que se acabó de generar y así y él se va a ir aumentando cada vez, qué es lo problemático con esto que si tú mantienes una conversación muy larga cada vez van a ser más tokens y al ser más tokens va a ser más costoso. Si tú lo estás poniendo trabajando con el modelo pne que trabaja por Toc eso te puede salir muy caro. Entonces por ahí es donde Ahí es donde yo decía que tienes que ser muy consciente con lo que con lo que estás trabajando, porque si no, Esa cuenta se te puede subir. Digamos que está hablando con la W s y bueno, estás trabajando con con itur si tú
Llenas mucho contexto y empiezas a preguntar, pues memoria y memoria y memoria y al final al final pues vas a tener una ventana de contexto tan grande que va a ser carísimo Entonces ese es el problema. O sea, básicamente todo eso que ves acá, memoria. Es memoria es memorias, memoria y cada Y si yo hago otra pregunta guardando esta memoria, él va a tener todo ese texto más todo este, entonces va a ser infinito, o sea, va a ser una una cantidad de de contexto gigante. Entonces por eso sean Muy cuidadosos. Cuando cuando estén almacenando contexto en las conversaciones no es bueno hacer conversaciones muy largas, que te guardes y muchos dos o tres preguntas atrás en el caso de que estás en un modelo de chat, pero no se lo recomiendo, pues tan al menos de que tengan dinero infinito que creería que nadie lo tiene cierto entonces para que lo sepan genial no, no está genial. Está genial. Esto es todo me gusta, no voy baja.
 Por compartir chicos, no sé si tiene más preguntas que ya estamos llegando como a la hacia la hora de cierre.
El silencio Recuerden que es como ya entonces Muchas no puedo como para para finalizar le eh Recuerden que el el repositorio, eh? Es compartido es relativamente fácil de ejecutar si tienen alguna duda me pueden escribir no hay ningún problema y y nada pues estamos ahí súper pendientes no José Julián Muchísimas gracias por compartir de nuevo la invitación que abierta Yo casi estoy seguro que tuviste que estudiar el tema otra vez porque sabías que te van a preguntar cosas y demás justamente enseñando es cuando aprendes aún más y te fuerzas a tener que hacerlo bien y digámoslo así Volverte un experto entonces este espacio es justo para eso Julián Gracias por atreverte te lo agradezco demasiado cualquiera que quiera hacerlo me escribe.
Abrimos el espacio el tema y la puerta está abierta justamente para eso es listo, hay muchos muchos proyectos, que pues no solamente uno puede trabajar como lenguaje muchos proyectos Pues que, eh? Que salen y pueden salir a productivo Entonces no anímense también a a hacer sus propios proyectos a mantener un repositorio bien poblado en en su github, o o donde sea que lo tengan que pues es bacano y pues nada trabaja en comunidades es es muy chévere para que lo lo tengan ahí pendiente, listo. Muchísimas gracias En este tiempo que queda les voy a robar solamente 5 o 10 minutos unas últimas actualizaciones va a compartirles pantalla por unos minutos más. Creo que ahí ya deberían estar viendo la pantalla cierto listo, no para dar un contexto, cómo está funcionando esto no sé si algunos sabían que Google tiene como una consola.
También que te da como $100 mensuales gratis para que tú los utilices en algunas de sus aplicaciones Entonces por qué muestro esto porque justamente para esto se está usando para la transcripción, se está sacando el audio de de las grabaciones y se pasa a través de este servicio de Google que te transforma al speech to text y esto lo convierte ya en un texto un sismo anti XD que tiene esa información con esto se está alimentando. Básicamente el modelo, eh? Resultados ya podemos ver algunos que son cambiamos por fin los títulos de las de las grabaciones que tenemos ya tiene un título más diciente falta mejorarlo en cositas, pero ya tenemos algunos resultados. Falta agregar descripciones, Porque todavía está fallando en eso, pero ya ya no es el el texto de la reunión, sino te hice un poco de qué se trata y servirá un poco de guía, La idea, es alimentarlo y hacerlo crecer con más datos.
Pero ahí vamos paso a paso, eh? Lo siguiente que era lo que les comentaba que también podemos ya sacarle provecho a lo que se ha estado haciendo, eh? Algunos saben que eh, de forma personal he trabajado en el mismo detector de anomalías, pero para eh, bienes raíces y creo que la sesión anterior era. Hemos alcanzado a ver un poco Cómo funcionaba el servicio ya como tal lo que ven aquí es el servicio que se utiliza para consultar este detección detección de anomalías para propiedades, específicamente para Antioquia Medellín y demás y todo esto, eh? Cómo lo que va a pasar con lo que nos presentó Julián que vamos a construir algo que nos va a servir en este caso, pues para el grupo de estudios, si hay dudas y demás, pues mejor que haya un asistente Que responda y no, que siempre se respetan preguntas algo así, sino como es asistente, que te va respondiendo de forma virtual, vamos a sacarle provecho a este, eh? Quieren comprar una casa. Creo que este modelo nos va a ayudar porque está encontrando ya las anomalías por
En los últimos 5 días encuentra las anomalías podemos cambiarlo a los últimos 10 y nos va a traer las anomalías con el precio con los apartamentos o casas con las que podamos comparar y ver si en realidad es una anomalía en el precio específicamente y podemos seguir creciendo nunca podrían ser 50 días 500 días, etcétera resultados, eh? Algo como esto que era el desafío que que yo tenía hace mucho tiempo y por eso nació la idea, quería comprar una casa que pereza tener que ver el portal todo el tiempo. Ojalá hubiera podido comprar una casa buena bonita y barata no pude en ese momento buenas noticias Ya estoy a punto. Espero cerca de vender el apartamento que había comprado y tener el capital para pues comprar uno que funcione con este mecanismo, eh? Eso era el problema que se quería resolver y un poco de resultado que quería mostrarles es, eh? Esta es la casa, por ejemplo la ubicación de la casa que está de referencia Esto está.
Al aeropuerto no me disculparán que no me sé bien los barrios San Bernardo Supongo que es por acá, es una casa. Estás siguientes son las locaciones de las demás casas con las que podemos comparar esa casa. Si se dan cuenta son muy cercanas y específicamente Este es el post de la casa que está en venta. Quizás bueno, por fotos no sean muy lindas y todo, pero por características tiene 150 m290 millones, se encuentra muy cerca en esa zona de San Bernardo eh, estrato 3 baños, cinco habitaciones bastante grande, este es como la la perla, La Perla que hay en ese mar de bienes raíces y con qué lo podemos comparar Bueno hay un post que ya venció que es este de acá es la segunda educación, eh? Este es un, eh? El otro post de otra casa que está en venta cerca de esa zona si se dan cuenta también de cerca del aeropuerto es ligeramente más pequeña, pero, eh? Es más cara. Sí, quizás tenga.
Características, eh? Más pisos tal vez y demás De hecho, tiene menos habitaciones, pero si se dan cuenta la otra es más grande y tras del hecho más barata algo tendrá no lo sabemos, pero tal que te ayuda al menos a filtrar esos casos en los que podría estar barata, igual está 380 millones, eh? Está mucho más cara. Se encuentran esta zona tres baños, cuatro habitaciones tiene una habitación menos Bueno ahí, no? Uno ya puede empezar a a buscar a encontrar entonces para ya sacarle provecho y bueno, este es el mapita ahí cuando ya yo quería conseguir en Bogotá se creó este canal Déjenme Les comparto, se creó este canal justo. Ahora lo voy a poner aquí en en público para que todo el mundo, pues pueda verlo y nada en este canal Cuál es el propósito del
Canal y sacarle provecho a este tipo de cosas que estamos haciendo se publicarán pues estas pequeñas Perlas pequeñas anomalías eventualmente Si llegan a tener alguna que les gustaría tener Quiero comprar una casa. Me gustaría que estuviera en esta en esta zona tal presupuesto tal número de habitaciones, eh? Tengo familia. Necesito tres habitaciones publican. Aquí está y quizás el modelo, le metemos los parámetros lo ejecutamos y nada Igual también la puerta que abiertas quieren invertir, me dice necesito plata para poder invertir entonces Machine learning. Está tocando barreras más más allá y les podemos sacar provecho y hagámosle para eso es este grupo también para sacarle provecho a hacer plata tener un mejor trabajo aprender o hacer comunidad con esto que nos gusta y va paso a paso, porque toma tiempo cada cada proyecto pero
Eventualmente con lo que explicó Julián también ahora de hecho por aquí está el lm mml rack por aquí está el canal que va a tomar en construcción porque el código todavía va ahí, pero sacamos el provecho es muy útil Podemos ser muy buenos. Yo todavía lo creo Podemos ser muy buenos en Machine learning competir con los mejores del mundo, por qué no y nada, Eso era todo por hoy muchachos Julián otra vez parce Muchísimas gracias Muchísimas gracias por participar, eh? Tocaba ya de pronto cuadrar una salida presencial para ir a comprar hamburguesas todos o algo así me tomé todo de origen, epa epa y nada chicos, bienvenidas, ahorita público otra vez ahí en el grupo, pues para colocar las actualizaciones y voten voten, que vamos a ver qué tema gana y hacemos algo también chévere, hacemos algo bacano para aprender por momento va ganando gafas, listo, dudas preguntas o
 Despegamos ya a mimir listo Muchas gracias Hasta luego ahí estamos en el grupo. Chao, que esté muy bien, muchas gracias, chao, Muchas gracias, gracias.